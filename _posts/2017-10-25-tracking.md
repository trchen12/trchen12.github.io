---
layout: post
title: Tracking 算法
data: 2017-10-25
header-img: "img/1.jpg"
categories: blog
description: Markdown tutorial
---

# 目标视觉跟踪（Visual Object Tracking)

**生成（generative）**
在当前对目标区域建模，下一zhen寻找与模型最相似的区域就是预测位置。比较著名的有卡尔曼滤波，粒子滤波，mean-shift.
<br/>
**判别（discriminative）**
检测跟踪 tracking by detection,经典的套路都是feature + ML. 比如之前的HOG+SVM，TLD算法。
现在一些相关滤波以及深度学习的方法已经逐渐显露头角，不过DL的端对端的特技还没有体现出来，貌似和一些相关滤波的算法还没有拉开很大差距。
*其实本来准备系统地介绍一下一些主流的track算法，太懒还是下次吧，下面的内容参考知乎。*
# EBT
今天介绍一个没有源代码的工作：Beyond local search:Tracking objects everywhere with instance-specific proposals //CVPR 2016. 说实话，没有源代码的论文读完多少有点意犹未尽。

原文我并没有仔细阅读过，不过在了解tracking的过程中，被该算法的稳定性吸引到了。
- 大多数检测跟踪算法，都假设前一阵跟踪准确，目标运动轨迹平滑，当前zhen在预测目标位置周围进行局部窗搜索，采用计算能力允许都搜索半径以获取最大速度，半径足够小以减少误匹配，这一假设在变形遮挡，目标快速和不规则运动，尤其是目标超出半径后失效。
- EBT跟踪算法，不局限于局部搜索窗，能够搞笑搜索整zhen，通过特例都类物体度量（Instance-specific objectness measure），生成少量高质量proposals，用以现有检测跟踪方法为核心的tracker对他们进行评估。在跟踪过程中，关注了proposals 提供的难误检样本更新目标模型，有助于抑制困难背景杂波引起的干扰，并且学习如何根据目标模型重排proposals。

**概括一下**
- 目的：用整zhen代替局部搜索窗。
- 方法：proposals减少候选样本。

简单来说，EdgeBoxes就是从图像中得到1k个候选框，这些框包含物体的概率比较高，而且每个框都有类物体分数（objectness score），可以简单理解成框包含物体的置信度。与检测问题不同，跟踪问题在轮廓和尺寸等几何结构方法方面有强烈的先验知识，所以EBT没有直接用EdgeBoxes给出的高分proposals，而是训练分类器对proposals重新打分，根据得分重新排列proposals，然后用于目标检测和模型更新，此外还加入了一项约束目标位置。

## 具体流程
输入图像，EdgeBoxes检测proposals， 保留objectness score大于threshold的候选框，然后对每个框，在边缘信息上计算类Harr小波特征。接下来，用训练好的linear SVM重新打分并排序。保留得分最高的200个候选框。linear SVM每5frame更新一次。其实这个过程就是根据跟踪目标先验知识（特例属性），**挑选了那些与跟踪目标在结构，尺寸方面比较相似的proposals**，所以叫instance-Specific Proposals。

## 检测阶段
我实在是太懒了，不想贴公式上去。不过最终的得分由**分类器f**和**平滑约束项s**组成，平滑约束其实就是抑制距离上一frame目标位置比较远的候选框得分。如果两个高分候选项，一个距离上一frame的目标较近，另一个距离比较远，我们有理由相信比较近的框更有可能是目标。**更新阶段**，训练样本同时采用了Instance—Specific Proposals给的候选框和目标样本附近的局部样本。其实该工作本身没什么特点，不过还是有一些可取之处的。

## 总结一波
1. 给出了proposal结合tracking的方法。
2. Object Proposal看起来让整frame搜索成为可能，而且自带降低误检率属性，这也是其高Robustness的原因。
3. 速度慢，不给源码, 都中了CVPR，心里还是没有一点B+树（摊手）
